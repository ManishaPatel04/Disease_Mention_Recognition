%%%% ijcai16.tex

\typeout{IJCAI-16 Instructions for Authors}

% These are the instructions for authors for IJCAI-16.
% They are the same as the ones for IJCAI-11 with superficical wording
%   changes only.

\documentclass{article}
% The file ijcai16.sty is the style file for IJCAI-16 (same as ijcai07.sty).
\usepackage{ijcai16}

% Use the postscript times font!
\usepackage{times}
\usepackage{graphicx}
\usepackage{url}

% the following package is optional:
%\usepackage{latexsym} 

% Following comment is from ijcai97-submit.tex:
% The preparation of these files was supported by Schlumberger Palo Alto
% Research, AT\&T Bell Laboratories, and Morgan Kaufmann Publishers.
% Shirley Jowell, of Morgan Kaufmann Publishers, and Peter F.
% Patel-Schneider, of AT\&T Bell Laboratories collaborated on their
% preparation.

% These instructions can be modified and used in other conferences as long
% as credit to the authors and supporting agencies is retained, this notice
% is not changed, and further modification or reuse is not restricted.
% Neither Shirley Jowell nor Peter F. Patel-Schneider can be listed as
% contacts for providing assistance without their prior permission.

% To use for other conferences, change references to files and the
% conference appropriate and use other authors, contacts, publishers, and
% organizations.
% Also change the deadline and address for returning papers and the length and
% page charge instructions.
% Put where the files are available in the appropriate places.

\title{$SL-FII$: Syntactic and Lexical Constraints with Frequency based Iterative Improvement for Disease Mention Recognition in News Headlines}

\author{Sidak Pal Singh, Sopan Khosla, Manisha Patel \\ 
Indian Institute of Technology (IIT) Roorkee  \\
sidakuec@iitr.ac.in, khoslasopan@gmail.com, manipubt@iitr.ac.in }
\begin{document}

\maketitle

\begin{abstract}
  News headlines are a vital source of information for the masses. Identifying diseases that are being spread or discovered is important to take necessary steps for their prevention and cure. Our system uses a syntactic and lexical constraint based approach which then goes through a frequency analysis phase to extract meaningful disease names. The evaluation of our approach on the 2015 news headlines dataset shows great recall and accuracy, illustrating the benefit of our approach. 
\end{abstract}

\section{Introduction}

Disease Mention Recognition involves identifying if a disease name occurs in a given
sentence. Over here, our aim is to extract disease names from the news headline text
and thus get a sense of latest diseases that people are suffering from. Biomedical Named
Entity Recognition (BNER) is the task of locating boundaries of the biomedical entities in
the text and tagging them with corresponding semantic type (e.g. disease, protein,
vitamins etc.). Previous research in this area has mainly focussed on gene/protein
mention recognition, and there hasn’t been much work in disease name recognition.
Difficulty of obtaining data (to train the model on) is one of the reasons for the same.

We aim to identify the patterns in the news headlines that contain diseases and use them
to generalize over diseases not seen until now. Correctly recognizing a disease mention is vital for further improvement of disease-centric knowledge extraction tasks. In this
project, we aim to use a contextual multi-gram model that identifies the word roots that
occur around disease mentions and extracts the sentence structure using rule-based
inference techniques. In other words, we use syntactic and lexical ($SL$) constraints to extract the disease names from headlines in an initial pass.  

The highlight of our approach is the ​Frequency-based Iterative Improvement ($FII$) that leads to more accurate results by weeding out the false positives.

We used a total of 664163 headlines for year 2014 and 408052 headlines for year 2015, using our inhouse IMM system. Our $SL-FII$ system was able to extract a total of 3157 and 5058 correct disease names for 2014 and 2015 respectively. 

\section{Related Work}
One of the essential requirements for a text mining application is the ability to identify relevant entities. In the past, several biomedical entity mention tasks have been explored such as gene/protein mention (Lu et al. 2011, Wei and Kao, 2011, Huang et al. 2011) and species/organism mention (Naderi et al. 2011). However, there have been few attempts in the domain of disease mention recognition. Even in the attempts that have been made, the usage of news headlines is unique to our approach.

In general clinical texts are different from texts of biomedical literature, e.g. composition of short, telegraphic phrases, use of implicit templates and pseudo-tables, as noted by Meystre et al. (2008). The data from news is even more different. Though there has been some work on identifying diseases in clinical texts, especially in the context of CMC Medical NLP Challenge2 and i2b2 Challenge3, these strategies can't be used in
practice for headlines data.

The UTU approach of Kaewphan et.al, 2014 focusses on the task of disease mention
recognition by using conditional random fields (CRFs) and vector space representations.
Their work also focuses on disease mention normalization, for which they combine word
vector representations and supervised machine learning to map the recognized
mentions to the corresponding UMLS concepts.

The currently used BNER systems are based on ML techniques such as CRFs, support
vector machines (SVMs) etc (Dai et al., 2009). These systems use either gene/protein
specific features (e.g. Greek alphabet matching) or post-processing rules (e.g. extension
of the identified mention boundaries to the left when a single letter with a hyphen
precedes them (Torii et al., 2009) which might not be as effective for other semantic type identification as they are for genes/proteins.

The only systematic experimental results reported for disease mention recognition in
biomedical literature using ML based approaches are published by Leaman and Gonzalez
(2008) and Leaman et al. (2009). They have used a CRF based BNER system named
BANNER which basically uses a set of orthographic, morphological and shallow syntactic features (Leaman and Gonzalez, 2008). 

Our system captures the way entities usually occur in news, which along with lexical constraints gives us the disease names. Apart from this, an advantage of our approach is that it can generalize for entities belonging to domains as different as cricket, politics etc. We illustrate this with an example in Section 3.3 . 



\begin{figure*}[t]
\centering
\includegraphics[width=6.4in]{img/Architecture2.png}
\caption{The architecture of our $SL-FII$ system.}
\label{fig:architecture}
\end{figure*}


\section{Proposed Solution}

Our solution involves four basic stages: Pre-processing, Relational Extraction, Frequency-based Iterative Improvement and Post-processing. The architecture \footnote{The code for our system can be found at \\ \url{https://github.com/sidak/Disease_Mention_Recognition}} of our $SL-FFI$ system is shown in Figure~\ref{fig:architecture}. 

\subsection{Pre-processing}

The first step of pre-processing is to clean the corpus(headlines) which primarily involves handling apostrphe inconsistencies. After this we used NLTK to tokenize the headlines, which subsequently go through PoS(Parts of Speech) tagging. Sometimes news headlines might contain grammatical inconsistencies like all words beginning with upper-case letters, incorrect or missing articles etc.  To handle such inconsistencies we used the following approach:
\begin{enumerate}

\item Convert headlines to lower-case and then compare the respective PoS tags of tokens with that of the original sentence.

\item If PoS tag differs, use lower-case form else use the original one.
\end{enumerate}

The symbols for the PoS tags and their corresponding description is shown in Table~\ref{tab:pos-notation}. Consider the following example headline,

\textit{"India Seeks Revenge From Australia"}

POS tagged: [('India', 'NNP'), ('Seeks', 'NNP'), ('Revenge', 'NNP'), ('From', 'NNP'), ('Australia', 'NNP')]\\

is compared to \textit{"india seeks revenge from australia"}

PoS tagged: [('india', 'NN'), ('seeks', 'VBZ'), ('revenge', 'NN'), ('from', 'IN'), ('australia', 'NN')]\\

PoS tag of India still portrays a noun, thus maintaining the original form, whereas the PoS tag of "Seeks" changes from NNP to VBZ (noun to verb), thus it is lower-cased.\\

So the given sentential form gets converted to \textit{"India seeks Revenge from Australia"}

POS tagged: [('India', 'NNP'), ('seeks', 'VBZ'), ('Revenge', 'NNP'), ('from', 'IN'), ('Australia', 'NNP')]


\subsection{Relational Extraction}

In this section we introduce two constraints on relation phrases: syntactic and lexical constraints. We also discuss how to generalize this relational extraction model for entities pertaining to different domains. 

\begin{table}[h]
  \caption{Notation used for PoS tags.}
  \centering
  \begin{tabular}{|l|l|} \hline
  \label{tab:pos-notation}
  \textbf{Symbol} & \textbf{Description} \\ \hline
  $DT$   & determiner\\ \hline
  $JJ$   & adjective\\ \hline
  $NN$   & noun, singular  \\ \hline
  $NNS$   & noun plural    \\ \hline
  $NNP$   & proper noun, singular      \\ \hline
  $NNPS$   & proper noun, plural	 \\ \hline
  $RB$   & adverb    \\ \hline
  $VB$   & verb, base form    \\ \hline
  $VBZ$   & verb, 3rd person\\ \hline
  
  \end{tabular}
\end{table}

\subsubsection{Lexical Constraints}

Disease names can be classified as entities. Since news headlines contain multiple entities, we need to identify the correct set of entities that correspond to disease names. In other words, we need to formalize a context that signifies the occurrence of disease names. 

In order to define the context, we mine certain word roots that indicate the presence of disease names in headlines. The word roots are obtained such that they cover a significant portion of disease containing headlines. We use a total of 10 word roots which are listed as follows: 

\begin{itemize}
\item 'diagnos' derivatives

\item 'outbreak' derivatives

\item 'cur' derivatives

\item 'vaccin' derivatives

\item 'die' derivatives

\item 'battling' derivatives

\item 'symptom' derivatives

\item 'treatment' derivatives

\item 'virus' derivatives

\item 'hospital' derivatives

\end{itemize}
The derivatives imply the lemmatized forms of the keywords mentioned along with
certain prepositions. For example, consider the derivatives of 'diagnos'\\

\textit{[mis]diagnos(e  $|$ es $|$ ed $|$ is) [with $|$ for $|$ of  $|$ by]}\\ 

After this, we formulate the rules by analysing the PoS tags of these lexical constraints i.e. PoS tags of the
different word root derivatives. Let us consider the example of formulation of rules for the
'diagnos' derivative 'diagnoses' as shown in Figure~\ref{fig:rules}


\begin{figure}[h]
\centering
\includegraphics[width=3.2in]{img/rules.png}
\caption{Rules for word root 'diagnos'.}
\label{fig:rules}
\end{figure}


\subsubsection{Syntactic Constraints}

The syntactic constraint serves two purposes. First, it eliminates incoherent extractions, and second, it
reduces uninformative extractions by capturing relation phrases
expressed by only certain combinations. 

The reason for it being that entities in news headlines generally occur as the regular expression given below:

\[E = [DT](JJ)^*(NN|NNP|NNS|NNPS)^+\]

Or in other words, phrases that contain an optional determiner or article (e.g. a, an)  followed by multiple optional adjectives (e.g. fractured) and atleast one occurence of noun (e.g. elbow, non-Hodgskins lymphoma) with a maximum chain length of four. 
 
Since disease names basically represent a kind of entities, the above syntactic constraint extracts the potential disease name phrases from news headlines. For obvious reasons, we omit the determiner or article (represented by the PoS tag: DT), in order to get the disease names. For example, in the below headline: \\

\textit{Former Butler forward Andrew Smith \textbf{diagnosed with} non-Hodgskins lymphoma 
}\\

The extracted disease name is \textit{'non-Hodgskins lymphoma'}.


\subsubsection{Generalization}
Since a basic entity is represented by the regular expression discussed earlier, our $SL-FII$ approach can be generalized for entities of other domains. This can be possible via simple modification of lexical constraints as per the context requirements. For example in order to identify the names of cricketers, we can use word roots like:

\begin{itemize}
\item 'wicket haul' derivatives
\item 'ton' derivatives
\end{itemize}

In the headlines below, we can successfully extract the cricketer's name using our $SL-FII$ model.\\

\textit{Gayle's 47-ball \textbf{ton} wipes out England }

\textit{Ashwin's 5 \textbf{wicket haul} takes India to the semis}


\subsection{Frequency-based Iterative Improvement}

In this section, we describe the details of the Frequency-based Iterative Improvement ($FII$) phase. 
The constraints formulated above are then used to extract disease names from the corpus in an initial pass. Next, the potential disease names are passed through the $FII$ phase.
The knowledge we obtained from the first pass represents the potential disease names in corpus based on $SL$(Syntactic-Lexical) analysis. In order to filter out false positives, we used $FII$ to give scores (based on probability of a word to be a disease name) to output of initial pass.
The approach is as follows and can be viewed in the form of equations from Equation~\ref{eq:1} to Equation~\ref{eq:5}.
Based on the training set, 
\begin{enumerate}

\item  A weight is assigned to lexical rules which corresponds to the probability that the phrase extracted from that lexical rule is a valid disease-name, as shown by Equation~\ref{eq:2}.

e.g. Rules like 'diagnosed with' gave better results than rules like 'Outbreak' (which also gave false positives for natural disasters). Thus much higher weight is associated with phrases output via 'diagnosed with'. 

\begin{figure*}[t!]

\begin{equation}
P(disease = True | phrase_j) = \sum_{all\_lexical\_rules} P(disease = True | phrase_j \cap lexical\_rule_i) \times P(phrase_j \cap lexical\_rule_i)
\label{eq:1} 
\end{equation}


\begin{equation}
P(disease = True | phrase_j \cap lexical\_rule_i) = P(disease = True | lexical\_rule_i) \\
 = weight \lbrack lexical\_rule_i \rbrack
\label{eq:2} 
\end{equation}

\begin{equation}
P(phrase \cap lexical\_rule_i) = P( phrase | lexical\_rule_i) \times  P(lexical\_rule_i)
\label{eq:3} 
\end{equation}

\begin{equation}
 P(phrase \cap lexical\_rule_i) = \frac{frequency \lbrack lexical\_rule_i] \lbrack phrase \rbrack  } {frequency\_in\_corpus \lbrack lexical\_rule_i \rbrack} \times \frac{frequency\_in\_corpus \lbrack lexical\_rule_i \rbrack} { size\_of\_total\_corpus}
\label{eq:4}
\end{equation}


\begin{equation}
DES \lbrack phrase_j \rbrack = \sum_{all\_lexical\_rules} weight \lbrack lexical\_rule_i \rbrack \times frequency \lbrack lexical\_rule_i \rbrack \lbrack phrase_j \rbrack  
\label{eq:5}
\end{equation}




\hrulefill
\end{figure*}


\item A normalized frequency is associated with the output phrases of pass-1 which corresponds to the probability of that phrase occuring with the lexical rule in consideration, as shown by Equation~\ref{eq:3} and Equation~\ref{eq:4}. 




\item Final score (also termed as Disease Expectancy Score($DES$) in Equation~\ref{eq:5}) is calculated taking into account the above probabilities for each rule. 

The score is equivalent to finding the probability that the phrase detected after intial pass is a disease.


\end{enumerate}

We hypothesise that the probability of a word being a disease is not determined from the word but from the accuracy that the lexical rule provides.
It can be shown using Bayesian network as given in the diagram. Markov's rule in this network validates our hypothesis. 

\begin{figure}[h]
\centering
\includegraphics[width=1in, height=3.2in]{img/disease.png}
\caption{Bayesian Network for $SL-FII$}
\label{fig:disease}
\end{figure}

$FII$ increases accuracy and reduces false positives based on probabilistic measures. Words with higher $DES$ have higher chances of being a valid disease-name. Phrases which occur with more rules are more reliable as a disease-name. 
e.g. Both Ebola and Tornado occur with 'outbreak', but Ebola can also occur with 'diagnosed with', 'died of' and several other rules whereas Tornado cannot. Thus $FII$ increases belief in Ebola as a valid disease-name. 

\subsection{Post-processing}
The results of $FII$ are sent for post-processing. Firstly we normalize the results and then analyse them based on its temporal distribution. Valid disease-names show distinct peaks whereas non-disease entities show uniform distribution over the specified time-interval. 

The constraints formulated above are then used to extract disease names from the corpus in an initial pass. Next, the potential disease names are passed through the $FII$ phase.

\section{Observations}

Table~\ref{tab:dis-freq} shows some of the extracted diseases with their corresponding frequency in the headlines for year 2014 and 2015. 

\begin{table}[h]
  \caption{Example of extracted diseases with frequency.}
  \centering
  \begin{tabular}{|l|l|l|} \hline
  \label{tab:dis-freq}
  \textbf{Disease Name} & \textbf{\# instances in 2014} & \textbf{\# instances in 2015}\\ \hline
  Cancer & 1072 & 494 \\ \hline
  Ebola & 182 & 990 \\ \hline
  HIV & 276 & 343 \\ \hline
  Measles & 72 & 141 \\ \hline
  Hodgkin lymphoma & 2 & 7 \\ \hline
  
  \end{tabular}
\end{table}


Table~\ref{tab:dis-headlines} shows a sample of potential disease names extracted from  headlines using syntactic and lexical (SL) constraints. The 5th headline is a sample false positive, where SL constraints incorrectly label Greece as a disease. But this will be handled once we pass it through $FII$, as illustrated in Table~\ref{tab:dis-DES}. The DES value of Greece is 0.32 which is much less than the DES values for other entities and can be filtered out as per the threshold accepted DES value. This threshold can be decided on the basis of accuracy requirements.  \\ 
\\

\begin{table}[h]
  \caption{Diseases extracted from headlines using $SL$ rules}
  \centering
  \begin{tabular}{|p{4cm}|p{2cm}|p{1.5cm}|} \hline
  \label{tab:dis-headlines}
  \textbf{Headline} & \textbf{Lexical rule} & \textbf{Disease name extracted} \\ \hline
  Healthcare worker in Scotland diagnosed with Ebola & diagnosed with & Ebola \\ \hline
  Beyonce Reaches Out to Grieving Family of Teen Who Died of Cancer & died of & Cancer \\ \hline
  Bird flu outbreak in Kottayam, Alappuzha & outbreak & Bird flu \\ \hline
  
   More details on Dan Uggla's concussion symptoms & symptoms & Concussion \\ \hline
  IMF rules out special treatment for Greece & treatment for & Greece \\ \hline
 
  
  \end{tabular}
\end{table}

\begin{table}[h]
  \caption{Disease Expectancy Scores after $FII$}
  \centering
  \begin{tabular}{|l|l|} \hline
  \label{tab:dis-DES}
  \textbf{Disease} & \textbf{DES} \\ \hline
  Ebola & 80.13 \\ \hline  
  Cancer & 14.66 \\ \hline  
  Bird Flu & 12.38 \\ \hline  
  Concussion & 1.86 \\ \hline  
  Greece & 0.32 \\ \hline
  
  \end{tabular}
\end{table}

Observed accuracy on test data (headlines of 2015), before post-processing, with extracted disease names sorted in descending order of their DES values is shown in Table~\ref{tab:acc-pre}.

\begin{table}[h]
  \caption{Accuracy on test data \textbf{before} post-processing}
  \centering
  \begin{tabular}{|l|l|} \hline
  \label{tab:acc-pre}
  \textbf{Top-k diseases (distinct)} & \textbf{\% accuracy} \\ \hline
  $k = 10$  & 100.00 \\ \hline  
  $k = 20$  & 100.00 \\ \hline  
  $k = 30$  & 86.67 \\ \hline  
  $k = 50$  & 80.00 \\ \hline  
  \end{tabular}
\end{table}
\vspace{-15pt}
\begin{table}[h!]
  \caption{Accuracy on test data \textbf{after} post-processing}
  \centering
  \begin{tabular}{|l|l|} \hline
  \label{tab:acc-post}
  \textbf{Top-k diseases (distinct)} & \textbf{\% accuracy} \\ \hline
  $k = 10$  & 100.00 \\ \hline  
  $k = 20$  & 100.00 \\ \hline  
  $k = 30$  & 96.67 \\ \hline  
  $k = 50$  & 92.00 \\ \hline  
  \end{tabular}
\end{table}

Once temporal post-processing is done, this accuracy will get improved by a great extent since uniformly occuring words like 'fight', 'water', 'state' etc. will be filtered out. The accuracy after post-processing is shown in Table~\ref{tab:acc-post}.
 
 
\section{Conclusion}
In this paper, we use lexical to first identify potential disease headlines and then syntactic constraints to extract the disease name phrase. Later, we pass the extracted disease names through $FII$ to weed out false diseases names based on the the previous experience gained in recognizing disease mentions with different word roots. As a result, the $FII$ phase improves significantly both the accuracy and recall of our system. In the future, we also plan to incorporate sequential pattern mining techniques to automatically identify syntactic and lexical constraints.  

%% The file named.bst is a bibliography style file for BibTeX 0.99c
\bibliographystyle{named}
\bibliography{ijcai16}

\end{document}

